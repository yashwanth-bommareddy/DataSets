{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca87b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3151213",
   "metadata": {},
   "source": [
    "### Data Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5abf00a",
   "metadata": {},
   "source": [
    "##### Reading the Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26416869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read csv with pandas:  68.469735622406 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_csv(\"Journal data.csv\")\n",
    "end = time.time()\n",
    "print(\"Time to read csv with pandas: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379bfd2",
   "metadata": {},
   "source": [
    "##### Reading the Data with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880ab16e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "EOF encountered while reading header. \nPass argument `sample_rows` and make sure the value of `sample` is large enough to accommodate that many rows of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\dataframe\\io\\csv.py\u001b[0m in \u001b[0;36mread_pandas\u001b[1;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhead_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParserError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m                 \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 5",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42368\\8401558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdask\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdask_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Journal data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0massume_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time to read csv with dask: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\dataframe\\io\\csv.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     ):\n\u001b[1;32m--> 744\u001b[1;33m         return read_pandas(\n\u001b[0m\u001b[0;32m    745\u001b[0m             \u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0murlpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\dataframe\\io\\csv.py\u001b[0m in \u001b[0;36mread_pandas\u001b[1;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParserError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"EOF\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    617\u001b[0m                 \u001b[1;34m\"EOF encountered while reading header. \\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[1;34m\"Pass argument `sample_rows` and make sure the value of `sample` \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: EOF encountered while reading header. \nPass argument `sample_rows` and make sure the value of `sample` is large enough to accommodate that many rows of data"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "start = time.time()\n",
    "dask_df = dd.read_csv(\"Journal data.csv\",sample_rows=1000000,assume_missing=True)\n",
    "end = time.time()\n",
    "print(\"Time to read csv with dask: \", (end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2a9c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})\n",
      "\n",
      "2023-05-12 22:42:17,574\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read csv with modin:  94.31718683242798 sec\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as mpd\n",
    "start = time.time()\n",
    "modin_df = mpd.read_csv(\"Journal data.csv\")\n",
    "end = time.time()\n",
    "print(\"Time to read csv with modin: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625e836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 22:44:26,105\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read csv with ray:  79.28154039382935 sec\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "start = time.time()\n",
    "ray_df = pd.read_csv(\"Journal data.csv\",engine='c')\n",
    "end = time.time()\n",
    "print(\"Time to read csv with ray: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378fb69",
   "metadata": {},
   "source": [
    "#### Ray is relatively a little faster in reading the data when compared to Pandas. While I have learnt that dask is the fastest to read data, the dask read functions fails to read the csv file above despite correcting the error by adding sample_rows parfameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae8cb5",
   "metadata": {},
   "source": [
    "#### In the second instance of running the code, Pandas was faster compared to both ray and modin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54acb673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51410 entries, 0 to 51409\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   paper_id          51410 non-null  object\n",
      " 1   doi               51410 non-null  object\n",
      " 2   body_text         51410 non-null  object\n",
      " 3   authors           51242 non-null  object\n",
      " 4   title             51410 non-null  object\n",
      " 5   journal           47388 non-null  object\n",
      " 6   abstract_summary  51410 non-null  object\n",
      " 7   country           51410 non-null  object\n",
      " 8   word_count        51410 non-null  int64 \n",
      " 9   language          51410 non-null  object\n",
      " 10  publish_time      51410 non-null  object\n",
      " 11  processed_text    51410 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f008b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>body_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract_summary</th>\n",
       "      <th>country</th>\n",
       "      <th>word_count</th>\n",
       "      <th>language</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd1afc537dace4f2cd2bcea5489396fc6620ffd0</td>\n",
       "      <td>10.5005/jp-journals-10005-1770</td>\n",
       "      <td>A sudden appearance of unidentified disease ch...</td>\n",
       "      <td>Ayyed, Ahmed Basheer</td>\n",
       "      <td>Dental Practice Infection Control&lt;br&gt;Measurem...</td>\n",
       "      <td>Int J Clin Pediatr Dent</td>\n",
       "      <td>A new coronavirus disease called COVID-19 has...</td>\n",
       "      <td>None</td>\n",
       "      <td>2970</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>['sudden', 'appearance', 'unidentified', 'dise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc8d5f7612c3024599e3b0b0c2a2743056800f39</td>\n",
       "      <td>10.4103/ijmm.ijmm_20_138</td>\n",
       "      <td>coronavirus of Group 2B. [15] Initial analysis...</td>\n",
       "      <td>Chakravarti, Anita.  Upadhyay, Shalini. &lt;br&gt;B...</td>\n",
       "      <td>Current Understanding, Knowledge Gaps and a&lt;b...</td>\n",
       "      <td>Indian Journal of Medical Microbiology</td>\n",
       "      <td>Review Article: Covid Series</td>\n",
       "      <td>None</td>\n",
       "      <td>3412</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>['coronavirus', 'group', 'initial', 'analysis'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f958977a0ba564b87aea0dbc569b454be2e2d3c</td>\n",
       "      <td>10.22037/ijpr.2020.113821.14506</td>\n",
       "      <td>New Coronavirus, SARS-CoV-2 (Severe Acute Resp...</td>\n",
       "      <td>Mohammadi Barzelighi, Hajar.  Daraei, Bahram....</td>\n",
       "      <td>Approaches for the Treatment of SARS-CoV-2&lt;br...</td>\n",
       "      <td>Iran J Pharm Res</td>\n",
       "      <td>The emergence of a novel Coronavirus disease</td>\n",
       "      <td>Iran</td>\n",
       "      <td>6819</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>['new', 'coronavirus', 'sars-cov', 'severe_acu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7484516fe4e4c02498b086a5b11ae908c5b4fcfb</td>\n",
       "      <td>10.12688/gatesopenres.13168.1</td>\n",
       "      <td>Communicable diseases constitute a global heal...</td>\n",
       "      <td>Paul, Alicia.  Upreti, Kamana.  Nepal,&lt;br&gt;Shr...</td>\n",
       "      <td>Rejoice architecture meets social norms to&lt;br...</td>\n",
       "      <td>Gates Open Res</td>\n",
       "      <td>Background: Each year, 600,000 children under...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>5320</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>['communicable', 'disease', 'constitute', 'glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f57034777b3dece6874a7d2e85bb942932490c10</td>\n",
       "      <td>10.5005/jp-journals-10005-1885</td>\n",
       "      <td>Coronavirus disease-2019 (COVID- 19) refers to...</td>\n",
       "      <td>Alsaleh, Majd M.  Sabbarini, Jumana M. &lt;br&gt;Al...</td>\n",
       "      <td>Changes in Behavior Management and Treatment&lt;...</td>\n",
       "      <td>Int J Clin Pediatr Dent</td>\n",
       "      <td>Objective: This study aims to assess the&lt;br&gt;k...</td>\n",
       "      <td>None</td>\n",
       "      <td>4246</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>['coronavirus', 'disease', 'covid', 'refers', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id                              doi  \\\n",
       "0  fd1afc537dace4f2cd2bcea5489396fc6620ffd0   10.5005/jp-journals-10005-1770   \n",
       "1  fc8d5f7612c3024599e3b0b0c2a2743056800f39         10.4103/ijmm.ijmm_20_138   \n",
       "2  0f958977a0ba564b87aea0dbc569b454be2e2d3c  10.22037/ijpr.2020.113821.14506   \n",
       "3  7484516fe4e4c02498b086a5b11ae908c5b4fcfb    10.12688/gatesopenres.13168.1   \n",
       "4  f57034777b3dece6874a7d2e85bb942932490c10   10.5005/jp-journals-10005-1885   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  A sudden appearance of unidentified disease ch...   \n",
       "1  coronavirus of Group 2B. [15] Initial analysis...   \n",
       "2  New Coronavirus, SARS-CoV-2 (Severe Acute Resp...   \n",
       "3  Communicable diseases constitute a global heal...   \n",
       "4  Coronavirus disease-2019 (COVID- 19) refers to...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                               Ayyed, Ahmed Basheer   \n",
       "1   Chakravarti, Anita.  Upadhyay, Shalini. <br>B...   \n",
       "2   Mohammadi Barzelighi, Hajar.  Daraei, Bahram....   \n",
       "3   Paul, Alicia.  Upreti, Kamana.  Nepal,<br>Shr...   \n",
       "4   Alsaleh, Majd M.  Sabbarini, Jumana M. <br>Al...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Dental Practice Infection Control<br>Measurem...   \n",
       "1   Current Understanding, Knowledge Gaps and a<b...   \n",
       "2   Approaches for the Treatment of SARS-CoV-2<br...   \n",
       "3   Rejoice architecture meets social norms to<br...   \n",
       "4   Changes in Behavior Management and Treatment<...   \n",
       "\n",
       "                                  journal  \\\n",
       "0                 Int J Clin Pediatr Dent   \n",
       "1  Indian Journal of Medical Microbiology   \n",
       "2                        Iran J Pharm Res   \n",
       "3                          Gates Open Res   \n",
       "4                 Int J Clin Pediatr Dent   \n",
       "\n",
       "                                    abstract_summary country  word_count  \\\n",
       "0   A new coronavirus disease called COVID-19 has...    None        2970   \n",
       "1                       Review Article: Covid Series    None        3412   \n",
       "2      The emergence of a novel Coronavirus disease     Iran        6819   \n",
       "3   Background: Each year, 600,000 children under...   Nepal        5320   \n",
       "4   Objective: This study aims to assess the<br>k...    None        4246   \n",
       "\n",
       "  language publish_time                                     processed_text  \n",
       "0       en   2020-01-01  ['sudden', 'appearance', 'unidentified', 'dise...  \n",
       "1       en   2020-01-01  ['coronavirus', 'group', 'initial', 'analysis'...  \n",
       "2       en   2020-01-01  ['new', 'coronavirus', 'sars-cov', 'severe_acu...  \n",
       "3       en   2020-01-01  ['communicable', 'disease', 'constitute', 'glo...  \n",
       "4       en   2020-01-01  ['coronavirus', 'disease', 'covid', 'refers', ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cf04d",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c8b24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Reading File  \n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def matching(df,config_data):\n",
    "    expected_col = list(config_data['columns'])\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col) == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3bfbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting store.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile store.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: Journal data.csv\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - paper_id\n",
    "    - doi\n",
    "    - body_text\n",
    "    - authors\n",
    "    - title\n",
    "    - journal\n",
    "    - abstract_summary\n",
    "    - country\n",
    "    - word_count\n",
    "    - language1\n",
    "    - publish_time\n",
    "    - processed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d2128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading config file\n",
    "import utility as util\n",
    "config_df = util.read_config_file(\"store.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db9dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_type': 'csv', 'dataset_name': 'file', 'file_name': 'Journal data.csv', 'table_name': 'edsurv', 'inbound_delimiter': ',', 'outbound_delimiter': '|', 'skip_leading_rows': 1, 'columns': ['paper_id', 'doi', 'body_text', 'authors', 'title', 'journal', 'abstract_summary', 'country', 'word_count', 'language1', 'publish_time', 'processed_text']}\n"
     ]
    }
   ],
   "source": [
    "print(config_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccec689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation failed\n",
      "Following File columns are not in the YAML file ['language']\n",
      "Following YAML columns are not in the file uploaded ['language1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matching(df,config_data):\n",
    "    expected_col = list(config_data['columns'])\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col) == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0\n",
    "matching(df,config_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c831ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "import gzip\n",
    "\n",
    "\n",
    "# Write csv in gz format in pipe separated text file (|)\n",
    "df.to_csv(\"Journal data.csv.gz\",\n",
    "          sep='|',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          quotechar='\"',\n",
    "          doublequote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4317faaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730181044"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(\"Journal data.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74865125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
